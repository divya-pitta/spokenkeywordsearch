{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import qparser\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# import pyttsx3\n",
    "# import speech_recognition as sr\n",
    "import glob\n",
    "# import pydub\n",
    "import asr.align\n",
    "# from gtts import gTTS\n",
    "import os\n",
    "import soundfile as sf\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import fbank\n",
    "# nltk.download('stopwords')\n",
    "import lshknn\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/python-KNN/\")\n",
    "import kdtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transDict = pickle.load(open('transDict2', 'r'))\n",
    "convertedDict = pickle.load(open('speechRecConvertDict2', 'r'))\n",
    "queryList = pickle.load(open('queryList2', 'r'))\n",
    "queryConvertedDict = pickle.load(open('queryConvertedDict2', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodeForQuery = []\n",
    "# encodeQueryDict = dict()\n",
    "# count = 0\n",
    "# for root, dirnames, filenames in os.walk('/home/ubuntu/autoencoder_encoding/'):\n",
    "#     for filename in fnmatch.filter(filenames, '*.wav.json'):\n",
    "#         curr = np.array(json.load(open(root+filename, 'r')))\n",
    "# #         print(curr.shape)\n",
    "#         for c in curr:\n",
    "#             encodeForQuery.append(c)\n",
    "#             encodeQueryDict[count] = filename\n",
    "#             count += 1\n",
    "# #             print(len(c))\n",
    "# #         print(len(curr))\n",
    "# #         print(len(curr[0]))\n",
    "#     print(count)\n",
    "#     print(len(encodeForQuery))\n",
    "    \n",
    "# encodeForAudio = []\n",
    "# encodeAudioDict = dict()\n",
    "# count = 0\n",
    "# for root, dirnames, filenames in os.walk('/home/ubuntu/autoencoder_encoding/'):\n",
    "#     for filename in fnmatch.filter(filenames, '*.flac.json'):\n",
    "#         curr = json.load(open(root+filename, 'r'))\n",
    "#         for c in curr:\n",
    "#             encodeForAudio.append(c)\n",
    "#             encodeAudioDict[count] = filename\n",
    "#             count += 1\n",
    "#             if(len(c)!=120):\n",
    "#                 print(len(c))\n",
    "# #         print(len(curr))\n",
    "# #         print(len(curr[0]))\n",
    "#     print(count)\n",
    "#     print(len(encodeForAudio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856254\n",
      "613\n",
      "2705\n"
     ]
    }
   ],
   "source": [
    "minQueryLen = 100000\n",
    "featSize = 30\n",
    "stride = 1\n",
    "# mfccDict = dict(list())\n",
    "audioMfcc = []\n",
    "audioPosnName = dict()\n",
    "count = 0\n",
    "j = 0\n",
    "for root, dirnames, filenames in os.walk('/home/ubuntu/DevData-AudioBooks/dev-clean/'):\n",
    "    for filename in fnmatch.filter(filenames, '*.wav'):\n",
    "        count += 1\n",
    "        with open(os.path.join(root, filename), 'rb') as f:\n",
    "            data, samplerate = sf.read(f)\n",
    "#         print(\"Read sounfile done\")\n",
    "        mfcc_feat = np.array(mfcc(data, samplerate))\n",
    "#         print(\"Mfcc done\")\n",
    "        mfcclen = len(mfcc_feat)\n",
    "        i = 0\n",
    "        while(i+featSize<mfcclen):\n",
    "            audioMfcc.append(mfcc_feat[i:i+featSize].flatten())\n",
    "#         if(len(mfcc_feat)<minQueryLen):\n",
    "#             minQueryLen = len(mfcc_feat)\n",
    "            audioPosnName[j] = filename.split('.')[0]\n",
    "            i += stride\n",
    "            j += 1\n",
    "print(len(audioMfcc))\n",
    "print(mfcclen)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfccNumpyArray = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minQueryLen = 100000\n",
    "# count = 0\n",
    "# for filename in glob.glob('/home/ubuntu/spokenkeywordsearch/GroundTruth/**/*.wav'):\n",
    "#     count += 1\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         data, samplerate = sf.read(f)\n",
    "# #     print(len(data))\n",
    "# #     print(samplerate)\n",
    "#     mfcc_feat = mfcc(data, samplerate, nfft=600)\n",
    "#     if(len(mfcc_feat)<minQueryLen):\n",
    "#         minQueryLen = len(mfcc_feat)\n",
    "# #     print(len(mfcc_feat))\n",
    "# print(minQueryLen)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "<closed file '/home/ubuntu/spokenkeywordsearch/GroundTruth/QueryAudio/1007.wav', mode 'rb' at 0x7faa10260ae0>\n",
      "169\n",
      "<closed file '/home/ubuntu/spokenkeywordsearch/GroundTruth/QueryAudio/379.wav', mode 'rb' at 0x7faa10416150>\n",
      "176225\n"
     ]
    }
   ],
   "source": [
    "minQueryLen = 100000\n",
    "maxQueryLen = 0\n",
    "mfccDict = dict(list())\n",
    "mfccNumpyArray = []\n",
    "mfccPosnName = dict()\n",
    "count = 0\n",
    "j = 0\n",
    "for root, dirnames, filenames in os.walk('/home/ubuntu/spokenkeywordsearch/GroundTruth/'):\n",
    "    for filename in fnmatch.filter(filenames, '*.wav'):\n",
    "        count += 1\n",
    "        with open(os.path.join(root, filename), 'rb') as f:\n",
    "            data, samplerate = sf.read(f)\n",
    "        mfcc_feat = np.array(mfcc(data, samplerate, nfft=600))\n",
    "        mfcclen = len(mfcc_feat)\n",
    "        if(minQueryLen>mfcclen):\n",
    "            minQueryLen = mfcclen\n",
    "            minId = f\n",
    "        if(maxQueryLen<mfcclen):\n",
    "            maxQueryLen = mfcclen\n",
    "            maxId = f\n",
    "        i = 0\n",
    "        while(i+featSize<mfcclen):\n",
    "            mfccNumpyArray.append(mfcc_feat[i:i+featSize].flatten())\n",
    "#         if(len(mfcc_feat)<minQueryLen):\n",
    "#             minQueryLen = len(mfcc_feat)\n",
    "            mfccPosnName[j] = filename.split('.')[0]\n",
    "            j += 1\n",
    "            i += stride\n",
    "print(minQueryLen)\n",
    "print(minId)\n",
    "print(maxQueryLen)\n",
    "print(maxId)\n",
    "print(len(mfccNumpyArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470\n"
     ]
    }
   ],
   "source": [
    "print(mfccPosnName[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 34642)\n",
      "3226\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lshknn\n",
    "\n",
    "# Make mock data\n",
    "# 2 features (rows), 4 samples (columns)\n",
    "res = mfccNumpyArray[0:5] + audioMfcc\n",
    "data = np.array(res,\n",
    "        dtype=np.float64)\n",
    "data = data.transpose()\n",
    "\n",
    "print(data.shape)\n",
    "print(len(mfccNumpyArray))\n",
    "print(len(mfccNumpyArray[0]))\n",
    "\n",
    "# Instantiate class\n",
    "c = lshknn.Lshknn(\n",
    "        data=data,\n",
    "        k=20,\n",
    "        threshold=0.2,\n",
    "        m=10,\n",
    "        slice_length=4)\n",
    "\n",
    "# Call subroutine\n",
    "knn, similarity, n_neighbors = c()\n",
    "\n",
    "# Check result\n",
    "# print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8845L 33938L 10386L 24740L 1148L 2655L 29603L 11316L 4239L 29509L\n",
      "  11308L 33841L 5206L 25424L 23589L 25343L 1442L 5058L 19691L 509L]\n",
      " [7476L 9054L 2695L 26697L 23920L 21555L 13018L 3044L 12021L 13779L\n",
      "  22372L 26857L 10710L 10688L 11876L 27846L 19015L 33384L 2197L 1535L]\n",
      " [27596L 14457L 23397L 3373L 14344L 22934L 23499L 22996L 14423L 14305L\n",
      "  3339L 9961L 3499L 1205L 23872L 1211L 3683L 103L 414L 998L]\n",
      " [29992L 17393L 29681L 4442L 4610L 22414L 29519L 24987L 29447L 11336L\n",
      "  28017L 13268L 17814L 33100L 3198L 10212L 22177L 3870L 947L 30107L]\n",
      " [8903L 11854L 2180L 31975L 31930L 6284L 11964L 14268L 2173L 4384L 1063L\n",
      "  4463L 2219L 32519L 16536L 6011L 569L 102L 380L 32527L]]\n"
     ]
    }
   ],
   "source": [
    "print(knn[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([])\n"
     ]
    }
   ],
   "source": [
    "print(set(knn[0]).intersection(set(knn[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2086-149220-0003\n",
      "2086-149220-0000\n",
      "2086-149220-0049\n"
     ]
    }
   ],
   "source": [
    "print(audioPosnName[1232-5])\n",
    "print(audioPosnName[1298-5])\n",
    "print(audioPosnName[1667-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(queryList[470])\n",
    "# # print(transDict['2086-149220-0003'])\n",
    "# # print(transDict['2086-149220-0000'])\n",
    "# # print(transDict['2086-149220-0049'])\n",
    "# for i in knn[0:5]:\n",
    "#     for j in i:\n",
    "#         if(audioPosnName[j-5]=='1272-141231-0026'):\n",
    "#             print(\"Got it\")\n",
    "#         else:\n",
    "#             print(audioPosnName[j-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestia \n",
      "8938\n",
      "8939\n",
      "8940\n",
      "8941\n",
      "8942\n",
      "8943\n",
      "8944\n",
      "8945\n"
     ]
    }
   ],
   "source": [
    "print((queryList[146]))\n",
    "for q in encodeAudioDict:\n",
    "    if(encodeAudioDict[q]=='1919-142785-0024.flac.json'):\n",
    "        print(q)\n",
    "# print(encodeQueryDict[3])\n",
    "# print(type(encodeForQuery[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 68062)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lshknn\n",
    "\n",
    "# Make mock data\n",
    "# 2 features (rows), 4 samples (columns)\n",
    "res = encodeForQuery[1947:1953] + (encodeForAudio)\n",
    "# print(len(res))\n",
    "# print(len(res[0]))\n",
    "data = np.array([np.array(x) for x in res])#, dtype=np.float64)\n",
    "data = data.transpose()\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# Instantiate class\n",
    "c = lshknn.Lshknn(\n",
    "        data=data,\n",
    "        k=20,\n",
    "        threshold=0.2,\n",
    "        m=10,\n",
    "        slice_length=4)\n",
    "\n",
    "# Call subroutine\n",
    "knn, similarity, n_neighbors = c()\n",
    "\n",
    "# Check result\n",
    "# print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52166L 18341L 57667L 57841L 58212L 4491L 4398L 31066L 51673L 51887L\n",
      "  54901L 17835L 54654L 6049L 58551L 2L 4L 2923L 166L 1280L]\n",
      " [6218L 8450L 26997L 47154L 64527L 8435L 64530L 64553L 41592L 33591L\n",
      "  32638L 3L 5L 25174L 2155L 1459L 1464L 2072L 1589L 1752L]\n",
      " [52166L 18341L 57667L 57841L 58212L 4491L 4398L 31066L 51673L 51887L\n",
      "  54901L 17835L 54654L 6049L 58551L 0L 4L 2923L 166L 1280L]\n",
      " [6218L 8450L 26997L 47154L 64527L 8435L 64530L 64553L 41592L 33591L\n",
      "  32638L 1L 5L 25174L 2155L 1459L 1464L 2072L 1589L 1752L]\n",
      " [52166L 18341L 57667L 57841L 58212L 4491L 4398L 31066L 51673L 51887L\n",
      "  54901L 17835L 54654L 6049L 58551L 0L 2L 2923L 166L 1280L]\n",
      " [6218L 8450L 26997L 47154L 64527L 8435L 64530L 64553L 41592L 33591L\n",
      "  32638L 1L 3L 25174L 2155L 1459L 1464L 2072L 1589L 1752L]]\n"
     ]
    }
   ],
   "source": [
    "print(knn[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illustration ginger\n",
      "\n",
      "12\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for k in knn[8938+6:8945+6]:\n",
    "    count = 0\n",
    "    for c in k:\n",
    "        count += 1\n",
    "        if(c>=2):\n",
    "#             print(encodeAudioDict[c-2])\n",
    "#             print(transDict[encodeAudioDict[c-2].split('.')[0]])\n",
    "            if('illustration' in transDict[encodeAudioDict[c-2].split('.')[0]]):\n",
    "                print(transDict[encodeAudioDict[c-2].split('.')[0]])\n",
    "                print(count)\n",
    "                print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for q in queryList:\n",
    "    if(q == 'illustration '):\n",
    "        print(count)\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2628L 3361L 3913L 4351L 4369L 4612L 4650L 3833L 2741L 2703L 2803L 2453L\n",
      "  2031L 1853L 1805L 1783L 1349L 493L 483L 288L]\n",
      " [2372L 20205L 19716L 19197L 20246L 54281L 38723L 3459L 37395L 37424L\n",
      "  61473L 22028L 60150L 22142L 60020L 26380L 49100L 58468L 1163L 2135L]\n",
      " [45547L 17090L 29077L 65732L 62279L 2575L 2571L 28896L 17027L 16951L\n",
      "  64973L 53298L 53791L 6011L 457L 28352L 1304L 1571L 2017L 573L]\n",
      " [26587L 2457L 16650L 19452L 54400L 53906L 14318L 53855L 41629L 50000L\n",
      "  9804L 23033L 39437L 16641L 18175L 25782L 55580L 7464L 58941L 49550L]\n",
      " [27037L 57822L 26173L 10149L 5472L 14286L 4216L 43902L 4967L 55457L\n",
      "  12262L 4937L 55388L 14859L 17407L 11478L 8370L 59299L 4648L 12879L]\n",
      " [9188L 55090L 53480L 52374L 21589L 21625L 11964L 66424L 43692L 52722L\n",
      "  361L 50363L 54018L 41540L 21390L 6197L 10917L 30344L 28141L 962L]]\n"
     ]
    }
   ],
   "source": [
    "print(knn[19813+6:19819+6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(audioMfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(mfccNumpyArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(audio=TEXT(stored=True), content=TEXT)\n",
    "if not os.path.exists(\"index\"):\n",
    "    os.mkdir(\"index\")\n",
    "index = create_in(\"index\", schema)\n",
    "writer = index.writer()\n",
    "for a in transDict:\n",
    "    writer.add_document(audio=u\"\"+a, content=u\"\"+transDict[a])\n",
    "writer.commit()\n",
    "searcher = index.searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892\n",
      "6256\n",
      "4\n",
      "0.142583120205\n"
     ]
    }
   ],
   "source": [
    "log = open('SimpleMFCCKNNSearch', 'a')\n",
    "commonCount = 0\n",
    "totalCount = 0\n",
    "maxMatching = 0\n",
    "i = 0\n",
    "while(i < (len(mfccPosnName))):\n",
    "    samePos = []\n",
    "    while(i+1<len(mfccPosnName) and mfccPosnName[i+1]==mfccPosnName[i]):\n",
    "        samePos.append(i)\n",
    "        i += 1\n",
    "    totalCount += 1\n",
    "    i -= 1\n",
    "    log.write('------------------------------------------------------------\\n')\n",
    "    log.write(mfccPosnName[i] + '\\n')\n",
    "    log.write(queryList[int(mfccPosnName[i])] + '\\n')\n",
    "    query = QueryParser(\"content\", index.schema, group=qparser.OrGroup).parse(queryList[int(mfccPosnName[i])])\n",
    "    results = searcher.search(query, limit=10)\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for res in results:\n",
    "        list1.append(res['audio'])\n",
    "    for ind in samePos:\n",
    "        for k in indices[ind]:\n",
    "            if(audioPosnName[k]):\n",
    "                log.write(audioPosnName[k]+\" : \")\n",
    "    #             print(str(audioPosnName[k]) + \"--\")\n",
    "                log.write(transDict[str(audioPosnName[k])] + \"\\n\")\n",
    "                list2.append(audioPosnName[k])\n",
    "    comm = len(set(list1).intersection(set(list2)))\n",
    "    if(comm>maxMatching):\n",
    "        maxMatching = comm\n",
    "    commonCount += comm\n",
    "    log.write(\"Matching : {0}\".format(comm))\n",
    "    log.flush()\n",
    "    i += 1\n",
    "print(commonCount)\n",
    "print(totalCount)\n",
    "print(maxMatching)\n",
    "print(commonCount/float(totalCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '6241-61946-0020' in transDict:\n",
    "    transDict['84-121123-0000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minQueryLen = 100000\n",
    "# featSize = 50\n",
    "# # mfccDict = dict(list())\n",
    "# audiofBank = []\n",
    "# audiofPosnName = dict()\n",
    "# count = 0\n",
    "# j = 0\n",
    "# for root, dirnames, filenames in os.walk('/home/ubuntu/DevData-AudioBooks/dev-clean/'):\n",
    "#     for filename in fnmatch.filter(filenames, '*.wav'):\n",
    "#         count += 1\n",
    "#         with open(os.path.join(root, filename), 'rb') as f:\n",
    "#             data, samplerate = sf.read(f)\n",
    "# #         print(\"Read sounfile done\")\n",
    "#         fbank_feat = np.array(fbank(data, samplerate))\n",
    "# #         print(\"Mfcc done\")\n",
    "#         mfcclen = len(mfcc_feat)\n",
    "#         i = 0\n",
    "#         while(i+featSize<mfcclen):\n",
    "#             audiofBank.append(fbank_feat[i:i+featSize].flatten())\n",
    "# #         if(len(mfcc_feat)<minQueryLen):\n",
    "# #             minQueryLen = len(mfcc_feat)\n",
    "#             audiofPosnName[j] = filename.split('.')[0]\n",
    "#             i += 25\n",
    "#             j += 1\n",
    "# print(len(audiofBank))\n",
    "# print(mfcclen)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
