{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from asr_evaluation import __main__\n",
    "import asr_evaluation\n",
    "import asr.align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "2703\n"
     ]
    }
   ],
   "source": [
    "transDict = dict()\n",
    "count = 0\n",
    "for filename in glob.iglob('/datasets/home/35/335/cs253wgf/291/Data/dev-clean/**/*.trans.txt', recursive=True):\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            vals = line.split(\" \", 1)\n",
    "            transDict[vals[0]] = vals[1].lower()\n",
    "    count += 1\n",
    "print(count)\n",
    "print(len(transDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from deepspeech.model import Model\n",
    "\n",
    "# These constants control the beam search decoder\n",
    "\n",
    "# Beam width used in the CTC decoder when building candidate transcriptions\n",
    "BEAM_WIDTH = 500\n",
    "\n",
    "# The alpha hyperparameter of the CTC decoder. Language Model weight\n",
    "LM_WEIGHT = 1.75\n",
    "\n",
    "# The beta hyperparameter of the CTC decoder. Word insertion weight (penalty)\n",
    "WORD_COUNT_WEIGHT = 1.00\n",
    "\n",
    "# Valid word insertion weight. This is used to lessen the word insertion penalty\n",
    "# when the inserted word is part of the vocabulary\n",
    "VALID_WORD_COUNT_WEIGHT = 1.00\n",
    "\n",
    "\n",
    "# These constants are tied to the shape of the graph used (changing them changes\n",
    "# the geometry of the first layer), so make sure you use the same constants that\n",
    "# were used during training\n",
    "\n",
    "# Number of MFCC features to use\n",
    "N_FEATURES = 26\n",
    "\n",
    "# Size of the context window used for producing timesteps in the input vector\n",
    "N_CONTEXT = 9\n",
    "\n",
    "def convert_samplerate(audio_path):\n",
    "    sox_cmd = 'sox {} --type raw --bits 16 --channels 1 --rate 16000 - '.format(audio_path)\n",
    "    try:\n",
    "        p = subprocess.Popen(sox_cmd.split(),\n",
    "                             stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "        output, err = p.communicate()\n",
    "\n",
    "        if p.returncode:\n",
    "            raise RuntimeError('SoX returned non-zero status: {}'.format(err))\n",
    "\n",
    "    except OSError as e:\n",
    "        raise OSError('SoX not found, use 16kHz files or install it: ', e)\n",
    "\n",
    "    audio = np.fromstring(output, dtype=np.int16)\n",
    "    return 16000, audio\n",
    "\n",
    "def getTextFromAudio(audio):\n",
    "    model =  \"/datasets/home/35/335/cs253wgf/models/output_graph.pb\"\n",
    "    alphabet = \"/datasets/home/35/335/cs253wgf/models/alphabet.txt\"\n",
    "    lm = \"/datasets/home/35/335/cs253wgf/models/lm.binary\"\n",
    "    trie = \"/datasets/home/35/335/cs253wgf/models/trie\"\n",
    "\n",
    "#     print('Loading model from file %s' % (model), file=sys.stderr)\n",
    "    model_load_start = timer()\n",
    "    ds = Model(model, N_FEATURES, N_CONTEXT, alphabet, BEAM_WIDTH)\n",
    "    model_load_end = timer() - model_load_start\n",
    "#     print('Loaded model in %0.3fs.' % (model_load_end), file=sys.stderr)\n",
    "\n",
    "    if lm and trie:\n",
    "#         print('Loading language model from files %s %s' % (lm, trie), file=sys.stderr)\n",
    "        lm_load_start = timer()\n",
    "        ds.enableDecoderWithLM(alphabet, lm, trie, LM_WEIGHT,\n",
    "                               WORD_COUNT_WEIGHT, VALID_WORD_COUNT_WEIGHT)\n",
    "        lm_load_end = timer() - lm_load_start\n",
    "#         print('Loaded language model in %0.3fs.' % (lm_load_end), file=sys.stderr)\n",
    "\n",
    "    fs , audio1 = wav.read(audio)\n",
    "    if fs != 16000:\n",
    "#         if fs < 16000:\n",
    "#             print('Warning: original sample rate (%d) is lower than 16kHz. Up-sampling might produce erratic speech recognition.' % (fs), file=sys.stderr)\n",
    "        fs , audio1 = convert_samplerate(audio)\n",
    "    audio_length = len(audio) * ( 1 / 16000)\n",
    "\n",
    "#     print('Running inference.', file=sys.stderr)\n",
    "    inference_start = timer()\n",
    "    textInferred = ds.stt(audio1, fs);\n",
    "#     print(textInferred)\n",
    "    inference_end = timer() - inference_start\n",
    "#     print('Inference took %0.3fs for %0.3fs audio file.' % (inference_end, audio_length), file=sys.stderr)\n",
    "    return textInferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeech.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "WER = 0\n",
    "for filename in glob.iglob('/datasets/home/35/335/cs253wgf/291/Data/dev-clean/**/*.wav', recursive=True):\n",
    "    vals = filename.rsplit(\"/\", 1)\n",
    "    audioFileName = (vals[1].split(\".\", 1))[0]\n",
    "    text1 = transDict[audioFileName]\n",
    "    text2 = getTextFromAudio(filename)\n",
    "    if(not text1):\n",
    "        text1 = \"\"\n",
    "    if(not text2):\n",
    "        text2 = \"\"\n",
    "    WER = WER + asr.align.calculate_wer(text1, text2)\n",
    "    count += 1\n",
    "print(\"Done\")\n",
    "print(\"Total count\", count)\n",
    "print(\"Average WER:\", WER/count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
